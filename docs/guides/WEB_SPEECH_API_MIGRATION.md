# Web Speech API Migration Guide

## Overview

The chatbot has been migrated from Whisper (backend-based) speech-to-text to **Web Speech API** (browser-based). This provides instant, client-side transcription without server requests.

## âœ… What Changed

### Frontend Changes

1. **New Hook: `useWebSpeechAPI.js`**

   - Custom React hook for Web Speech API integration
   - Handles speech recognition lifecycle
   - Language support for English and Malay
   - Error handling for browser compatibility

2. **Updated `ChatInput.jsx`**

   - Removed all audio recording code (MediaRecorder, AudioContext)
   - Integrated `useWebSpeechAPI` hook
   - Simplified voice input flow
   - Auto-sends transcribed text when speech ends

3. **Simplified `VoiceInput.jsx`**

   - Removed audio level visualization (Web Speech API doesn't expose audio data)
   - Animated listening indicator
   - Changed color from red (recording) to blue (listening)

4. **Cleaned `ChatBox.jsx`**

   - Removed all audio-related state and refs
   - Simplified component prop passing
   - Much cleaner component structure

5. **Updated `InteractionTab.jsx` (Settings)**
   - Language options now use Web Speech API locale codes:
     - `en-US` - English (United States)
     - `en-GB` - English (United Kingdom)
     - `ms-MY` - Bahasa Melayu (Malay)
   - Updated help text to mention Web Speech API

### Backend Changes

âŒ **NOT NEEDED ANYMORE:**

- `POST /transcribe` endpoint (backend/routes/ai.py)
- `transcribe_audio_file()` function (backend/utils/chat.py)
- Whisper model dependencies
- OpenAI Whisper API integration
- Database connection for transcription

## ğŸš€ Key Features

### Advantages of Web Speech API

âœ… **Instant Transcription** - No server roundtrip, results appear instantly  
âœ… **Zero Dependencies** - Built into Chrome, Edge, and Chromium browsers  
âœ… **Privacy** - Audio never leaves your browser  
âœ… **Multilingual** - Supports 100+ languages  
âœ… **Reduced Latency** - No network delay  
âœ… **Lower Costs** - No API fees

### Supported Browsers

- âœ… Chrome/Chromium (Full support)
- âœ… Edge (Full support)
- âœ… Opera (Full support)
- âš ï¸ Safari (Partial - webkit prefix required)
- âŒ Firefox (Not supported)

## ğŸ“ Language Configuration

Edit [frontend/src/components/settings/InteractionTab.jsx](frontend/src/components/settings/InteractionTab.jsx) to add more languages:

```jsx
<option value="es-ES">EspaÃ±ol (Spanish)</option>
<option value="fr-FR">FranÃ§ais (French)</option>
<option value="de-DE">Deutsch (German)</option>
<option value="zh-CN">ä¸­æ–‡ (Simplified Chinese)</option>
<option value="ja-JP">æ—¥æœ¬èª (Japanese)</option>
// ... etc
```

### Supported Language Codes

Web Speech API supports BCP 47 language tags:

| Language             | Code    |
| -------------------- | ------- |
| English (US)         | `en-US` |
| English (UK)         | `en-GB` |
| Malay                | `ms-MY` |
| Spanish              | `es-ES` |
| French               | `fr-FR` |
| German               | `de-DE` |
| Chinese (Simplified) | `zh-CN` |
| Japanese             | `ja-JP` |

See [MDN Web Speech API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition) for complete list.

## ğŸ”§ Implementation Details

### useWebSpeechAPI Hook

Located at: [frontend/src/hooks/useWebSpeechAPI.js](frontend/src/hooks/useWebSpeechAPI.js)

```javascript
const {
  isListening, // Boolean - currently listening?
  transcript, // String - recognized text so far
  isFinal, // Boolean - is this the final result?
  error, // String - error message if any
  isSupported, // Boolean - is Web Speech API supported?
  startListening, // Function - start listening
  stopListening, // Function - stop listening
  abort, // Function - abort recognition
} = useWebSpeechAPI();
```

### Usage in ChatInput

```jsx
import useWebSpeechAPI from '../../hooks/useWebSpeechAPI';

const ChatInput = ({ ... }) => {
  const { isListening, transcript, isFinal, startListening, stopListening } = useWebSpeechAPI();

  const handleVoiceClick = () => {
    if (!isListening) {
      startListening();
    } else {
      stopListening();
    }
  };

  // Auto-send when speech ends
  React.useEffect(() => {
    if (!isListening && isFinal && transcript) {
      onSendMessageWithText(transcript, 'voice');
    }
  }, [isListening, isFinal]);
};
```

## ğŸ› Error Handling

Web Speech API provides specific error types:

| Error           | Meaning              | User Action                 |
| --------------- | -------------------- | --------------------------- |
| `no-speech`     | No sound detected    | Speak louder/clearer        |
| `audio-capture` | Microphone not found | Check microphone connection |
| `not-allowed`   | Permission denied    | Allow microphone in browser |
| `network`       | Network error        | Check internet connection   |
| `aborted`       | Recognition aborted  | Try again                   |

See [useWebSpeechAPI.js](frontend/src/hooks/useWebSpeechAPI.js#L34) for error messages.

## ğŸ§ª Testing

### Manual Testing

1. Open app in Chrome/Edge
2. Navigate to chat page
3. Click microphone icon ğŸ¤
4. Speak clearly
5. Text should appear immediately
6. Message auto-sends when you stop talking

### Test Different Languages

1. Go to Settings â†’ Interaction
2. Select language (English or Malay)
3. Test voice input with that language

### Browser Compatibility Test

```javascript
// Test in browser console
const SpeechRecognition =
  window.SpeechRecognition || window.webkitSpeechRecognition;
console.log(SpeechRecognition ? "Supported" : "Not supported");
```

## âš™ï¸ Configuration

### Change Default Language

Edit [frontend/src/pages/user/Settings.jsx](frontend/src/pages/user/Settings.jsx#L36):

```javascript
localStorage.getItem("voiceLanguage") || "en-US"; // Change 'en-US' to your preferred language
```

### Add More Languages

Edit [frontend/src/components/settings/InteractionTab.jsx](frontend/src/components/settings/InteractionTab.jsx#L27):

```jsx
<select>
  <option value="en-US">English (US)</option>
  <option value="en-GB">English (UK)</option>
  <option value="ms-MY">Bahasa Melayu</option>
  {/* Add more languages here */}
  <option value="es-ES">EspaÃ±ol</option>
</select>
```

## ğŸš¨ Known Limitations

1. **Browser Dependent** - Only works in supported browsers
2. **No Audio Level** - Can't show real-time audio visualization
3. **No Offline Mode** - Still requires internet (uploads to Google servers)
4. **Recognition Timeout** - Stops after ~30 seconds of silence
5. **No Streaming** - Full audio sent at once, not streaming

## ğŸ“š Files Modified

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useWebSpeechAPI.js (NEW)
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â”œâ”€â”€ ChatInput.jsx (UPDATED)
â”‚   â”‚       â”œâ”€â”€ ChatBox.jsx (UPDATED)
â”‚   â”‚       â””â”€â”€ VoiceInput.jsx (UPDATED)
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ settings/
â”‚   â”‚       â””â”€â”€ InteractionTab.jsx (UPDATED)
â”‚   â””â”€â”€ pages/
â”‚       â””â”€â”€ user/
â”‚           â””â”€â”€ Settings.jsx (UPDATED)
```

## âŒ Files/Code Removed

```
backend/
â”œâ”€â”€ routes/ai.py
â”‚   â””â”€â”€ @router.post("/transcribe") - REMOVED
â”œâ”€â”€ utils/chat.py
â”‚   â””â”€â”€ transcribe_audio_file() - REMOVED
â”‚   â””â”€â”€ WHISPER_AVAILABLE - REMOVED
â”‚   â””â”€â”€ OPENAI_API_AVAILABLE - REMOVED

Dependencies no longer needed:
- openai-whisper
- pyaudio (if used)
- torch (if used for local Whisper)
```

## ğŸ”„ Migration Checklist

- [x] Create Web Speech API hook
- [x] Update ChatInput to use hook
- [x] Remove audio recording code
- [x] Update VoiceInput visualization
- [x] Clean up ChatBox state/refs
- [x] Update Settings language options
- [x] Update default language codes
- [ ] Test in different browsers
- [ ] Test with English speakers
- [ ] Test with Malay speakers
- [ ] Update backend `/transcribe` endpoint (optional - can be removed)
- [ ] Update documentation

## ğŸ“ Support

If you encounter issues:

1. **Check browser console** (F12 â†’ Console tab)
2. **Verify microphone permissions** in browser settings
3. **Test in Chrome/Edge first** (best compatibility)
4. **Try a different language** in Settings
5. **Restart browser** and try again

## ğŸ“ Resources

- [MDN Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [SpeechRecognition API](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition)
- [BCP 47 Language Tags](https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry)

---

**Status**: âœ… Migration Complete  
**Date**: January 2026  
**Browser Support**: Chrome, Edge, Opera  
**Fallback**: Text input always available
